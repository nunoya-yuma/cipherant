# パーソナルリサーチエージェント：プロジェクト設計書

## プロジェクト名
Cipherant - Cipher（暗号/情報）+ Servant（使用人）を組み合わせた言葉。情報を扱う従者という意味

## プロジェクト概要
LLMを活用したローカル処理優先の個人向け調査・情報整理アシスタント。複数の情報源からデータを収集・統合し、ユーザーの文脈に合わせた深い洞察を提供する。Rustで実装し、高性能・プライバシー保護・カスタマイズ性を重視する。

## 機能概要

### 1. 情報収集と統合
- **マルチソース検索**: Web、ローカルファイル、PDF、個人ノートから同時に関連情報を収集
- **継続的モニタリング**: 指定トピックの新情報自動通知
- **データインポート**: 既存ノート・ブックマーク取り込み

### 2. インテリジェント処理
- **コンテキスト対応要約**: ユーザーの知識レベル・関心に合わせた要約生成
- **関連性分析**: 新情報と過去調査の関連性分析、知識の穴を特定
- **事実確認**: 複数ソースからの情報比較で信頼性評価

### 3. インタラクティブな調査支援
- **会話型調査**: 自然な会話での調査深掘り
- **調査シナリオ**: 調査パターンのテンプレート化・再利用
- **思考整理**: 調査中のアイデア記録・関連情報自動リンク

### 4. プラクティカルな出力
- **カスタム形式**: レポート、メモ、プレゼン資料など様々な形式で出力
- **引用トレース**: 全情報源の正確な記録・引用
- **アクションアイテム抽出**: 調査結果から次のアクションを自動抽出

## 技術アーキテクチャ

```
┌─────────────────────────────────────────────────────────────────┐
│                      ユーザーインターフェース                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐   ┌──────────────┐   │
│  │   CLI    │  │   GUI    │  │   API    │   │ ブラウザ拡張    │   │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘   └──────┬───────┘   │
└───────┼──────────────┼──────────────┼──────────────┼────────────┘
        │              │              │              │
┌───────▼──────────────▼──────────────▼──────────────▼────────────┐
│                         コアエンジン                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐  │
│  │ クエリ解析         │  │ 調査計画生成     │  │ レスポンス合成     │  │
│  └────────┬────────┘  └────────┬────────┘  └────────┬────────┘  │
│           │                    │                    │           │
│  ┌────────▼────────────────────▼────────────────────▼────────┐  │
│  │                      オーケストレーター                         │  │
│  └────────┬────────────────────┬────────────────────┬────────┘  │
└───────────┼────────────────────┼────────────────────┼───────────┘
            │                    │                    │
┌───────────▼────────┐  ┌────────▼───────┐  ┌────────▼───────────┐
│   情報収集モジュール │  │  LLMコネクタ   │  │   ストレージモジュール │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │  ウェブスクレイパー││  ││ OpenAI     │ │  │ │ベクトルDB管理   │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │  PDFプロセッサ   ││  ││ Gemini     │ │  │ │メタデータストア  │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
│ ┌─────────────────┐│  │┌─────────────┐ │  │ ┌─────────────────┐ │
│ │ローカルファイル  ││  ││ ローカルモデル│ │  │ │  履歴管理     │ │
│ └─────────────────┘│  │└─────────────┘ │  │ └─────────────────┘ │
└────────────────────┘  └────────────────┘  └─────────────────────┘
```

## コンポーネント詳細

### 1. ユーザーインターフェース層
- **CLI**: Rust製の高速なコマンドラインツール（`clap`等利用）
- **GUI**: Tauriフレームワークを使用したデスクトップアプリ（後期フェーズ）

### 2. コアエンジン
- **クエリ解析**: ユーザー入力を解析し意図を理解
- **調査計画生成**: 複数のデータソースへのクエリを最適化
- **レスポンス合成**: 複数ソースからの情報を統合
- **オーケストレーター**: 全モジュール間の通信と処理フローを制御

### 3. 情報収集モジュール
- **ウェブスクレイパー**: 並列処理でウェブ情報を効率的に収集
- **PDFプロセッサ**: PDF文書からテキスト・構造を抽出
- **ローカルファイル**: ファイルシステムから関連文書を検索・解析

### 4. LLMコネクタ
- **マルチバックエンド**: OpenAI、Gemini、ローカルモデルに対応
- **プロンプト管理**: 効果的なプロンプトテンプレートの管理
- **コンテキスト最適化**: トークン制限内で関連情報を最大化

### 5. ストレージモジュール
- **ベクトルDB**: セマンティック検索のための埋め込みストレージ（Qdrant等）
- **メタデータストア**: ドキュメント属性、タグ、関連情報の管理
- **履歴管理**: ユーザーの調査履歴と進行状況の保存

## 技術スタック（Rustクレート）

### コア機能
- **tokio**: 非同期ランタイム
- **reqwest**: HTTPクライアント（ウェブ情報取得）
- **rayon**: データ並列処理
- **serde** + **serde_json**: シリアライゼーション
- **clap**: コマンドラインインターフェース

### LLMインテグレーション
- **llm-chain-rs**: ローカルLLM統合フレームワーク
- **candle**: Rustネイティブの機械学習実行環境
- **tokenizers**: トークナイザー実装

### 情報処理
- **lopdf** / **pdf**: PDF処理
- **scraper** / **select**: HTMLスクレイピング
- **tantivy**: 全文検索エンジン
- **qdrant-client**: ローカルベクトルデータベース

### UI（段階的に実装）
- **crossterm** / **tui**: ターミナルUI（初期段階）
- **tauri**: デスクトップGUI（後期段階）

## プロジェクト構造

```
personal_research_agent/
├── Cargo.toml                  # 依存関係定義
├── src/
│   ├── main.rs                 # エントリーポイント
│   ├── cli/                    # CLIインターフェース
│   │   ├── mod.rs
│   │   └── commands.rs
│   ├── core/                   # コアエンジン
│   │   ├── mod.rs
│   │   ├── query_analyzer.rs   # クエリ解析
│   │   ├── planner.rs          # 調査計画生成
│   │   ├── orchestrator.rs     # 処理フロー制御
│   │   └── response_builder.rs # 応答合成
│   ├── collectors/             # 情報ソース
│   │   ├── mod.rs
│   │   ├── web.rs              # ウェブスクレイピング
│   │   ├── pdf.rs              # PDF処理
│   │   └── local_files.rs      # ローカルファイル検索
│   ├── llm/                    # LLMコネクタ
│   │   ├── mod.rs
│   │   ├── model.rs            # モデルインターフェース
│   │   ├── local_model.rs      # ローカルモデル実装
│   │   ├── prompt.rs           # プロンプトテンプレート
│   │   └── api_model.rs        # API接続用（オプション）
│   ├── storage/                # ストレージ
│   │   ├── mod.rs
│   │   ├── vector_db.rs        # ベクトルDB操作
│   │   ├── metadata.rs         # メタデータ管理
│   │   └── history.rs          # 履歴保存
│   └── utils/                  # ユーティリティ
│       ├── mod.rs
│       ├── text_processing.rs  # テキスト処理
│       └── config.rs           # 設定管理
└── tests/                      # テスト
```

## 開発フェーズ

### フェーズ1: 基盤実装（2週間）
- プロジェクト構造セットアップ
- CLIインターフェース基本実装
- シンプルなウェブスクレイピング
- LLMインテグレーション（初期モデル）

### フェーズ2: コア機能実装（3週間）
- 複数情報源からのデータ取得
- ベクトルDBでの保存と検索
- プロンプトテンプレート実装
- 基本的な会話コンテキスト

### フェーズ3: 高度機能実装（4週間）
- PDFや他の文書形式の処理
- メタデータと関連性分析
- 調査計画の最適化
- 並列処理とパフォーマンス改善

### フェーズ4: UI改善とテスト（3週間）
- リッチCLIまたは簡易GUIの実装
- エラーハンドリングとロギング強化
- ユーザーテスト
- パッケージング

## LLMモデル選定
- OpenAI API
- Gemini API
- ローカルモデル（Llama、Mixtral、Phi-3など）

## 実装方針
- 完全ローカル実装を優先
- プライバシー保護を重視
- Rust学習を兼ねた実装
